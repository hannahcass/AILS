{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit:  2022.03.5\n"
     ]
    }
   ],
   "source": [
    "#from fcd import get_fcd, load_ref_model, canonical_smiles, get_predictions, calculate_frechet_distance\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pickle\n",
    "import rdkit\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Ignore some warnings from RDKIT and keras\n",
    "from rdkit import RDLogger, Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load methods from the FCD library\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"RDKit: \", rdkit.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"smiles_train.txt\", header=None)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_canonical(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return Chem.MolToSmiles(mol, canonical=True)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_canonical \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mapply(to_canonical)\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\dlnn\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\dlnn\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\dlnn\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\dlnn\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mto_canonical\u001b[1;34m(smiles)\u001b[0m\n\u001b[0;32m      2\u001b[0m mol \u001b[39m=\u001b[39m Chem\u001b[39m.\u001b[39mMolFromSmiles(smiles)\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m mol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mreturn\u001b[39;00m Chem\u001b[39m.\u001b[39;49mMolToSmiles(mol, canonical\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      5\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_canonical = data.apply(to_canonical).dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_canonical.to_csv(\"canonical_smiles_train.txt\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_canonical = pd.read_csv(\n",
    "    \"canonical_smiles_train.txt\", header=None, squeeze=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                COc1ccc(N2CCN(C(=O)c3cc4ccccc4[nH]3)CC2)cc1\n",
       "1            c1ccc(CCCNC2CCCCN(CCOC(c3ccccc3)c3ccccc3)C2)cc1\n",
       "2                             Nc1nc(O)c(Br)c(-c2cccc(O)c2)n1\n",
       "3               CCc1nc2ccc(Br)cc2c(=O)n1-c1nc2c(C)cc(C)cc2s1\n",
       "4            O=c1cnn(-c2ccc(S(=O)(=O)N3CCCCC3)cc2)c(=O)[nH]1\n",
       "                                 ...                        \n",
       "1036638                  CCOc1ccc(-n2c(SC)nc3c(c2=O)SCC3)cc1\n",
       "1036639        Nc1ncnc2c1nc(I)n2C1SC(COC(=O)c2ccccc2)C(O)C1O\n",
       "1036640              O=C(O)CCc1sc(C=C2NC(=O)CS2)nc1-c1ccccn1\n",
       "1036641    CN(c1ncnc2[nH]ccc12)C1CC(CS(=O)(=O)N2CCC(C#N)C...\n",
       "1036642    CCc1ccc(S(=O)(=O)NC2c3cc(C(=O)NCCc4c[nH]cn4)cc...\n",
       "Name: 0, Length: 1036643, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, val_data = train_test_split(data, test_size=1/6, random_state=42)\n",
    "train_data, val_data = train_test_split(\n",
    "    data_canonical, test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = sorted(list(set(''.join(data))))\n",
    "max_length = max([len(smile) for smile in data]) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_smiles(smiles, charset, max_length):\n",
    "    indices = [charset.index(char) for char in smiles]\n",
    "    padded_indices = indices + [0] * (max_length - len(indices))\n",
    "    data = torch.tensor(padded_indices[:-1], dtype=torch.long)\n",
    "    target = torch.tensor(padded_indices[1:], dtype=torch.long)\n",
    "    return data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, smiles_data, charset, max_length):\n",
    "        self.smiles_data = smiles_data\n",
    "        self.charset = charset\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_smiles = self.smiles_data[index % len(self.smiles_data)]\n",
    "        data, target = vectorize_smiles(\n",
    "            input_smiles, self.charset, self.max_length)\n",
    "        one_hot_data = torch.zeros(data.size(0), len(self.charset))\n",
    "        one_hot_data.scatter_(1, data.unsqueeze(1), 1)\n",
    "        return one_hot_data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SMILESDataset(train_data, charset, max_length)\n",
    "val_dataset = SMILESDataset(val_data, charset, max_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "input_size = len(charset)\n",
    "hidden_size = 128\n",
    "output_size = len(charset)\n",
    "num_layers = 1\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESLSTM(nn.Module):\n",
    "    def __init__(self, input_size=input_size, hidden_size=512, output_size=output_size, num_layers=4):\n",
    "        super(SMILESLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size,\n",
    "                             num_layers, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size,\n",
    "                             num_layers, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.lstm3 = nn.LSTM(hidden_size, hidden_size,\n",
    "                             num_layers, batch_first=True)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.lstm4 = nn.LSTM(hidden_size, hidden_size,\n",
    "                             num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        out = self.dropout1(out)\n",
    "        out, _ = self.lstm2(out, (h0, c0))\n",
    "        out = self.dropout2(out)\n",
    "        out, _ = self.lstm3(out, (h0, c0))\n",
    "        out = self.dropout3(out)\n",
    "        out, _ = self.lstm4(out, (h0, c0))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SMILESLSTM(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m output \u001b[39m=\u001b[39m model(one_hot_data\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     12\u001b[0m loss \u001b[39m=\u001b[39m criterion(output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), target)\n\u001b[1;32m---> 13\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     16\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\dlnn\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\dlnn\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_count = 0\n",
    "    for one_hot_data, target in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "        one_hot_data, target = one_hot_data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(one_hot_data.float())\n",
    "\n",
    "        loss = criterion(output.transpose(1, 2), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_count += 1\n",
    "\n",
    "    avg_train_loss = train_loss / train_count\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_count = 0\n",
    "    with torch.no_grad():\n",
    "        for one_hot_data, target in tqdm(val_loader, desc=f\"Validating Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "            one_hot_data, target = one_hot_data.to(device), target.to(device)\n",
    "            output = model(one_hot_data.float())\n",
    "            loss = criterion(output.transpose(1, 2), target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_count\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"trained_model_3.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unvectorize_smiles(vector, charset):\n",
    "    smiles = \"\"\n",
    "    for index in vector:\n",
    "        if index == len(charset) - 1:  # End of sequence token\n",
    "            break\n",
    "        smiles += charset[index]\n",
    "    return smiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, input_smiles, charset, max_length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = vectorize_smiles(input_smiles, charset, max_length)\n",
    "        one_hot_data = torch.zeros(1, data[0].size(0), len(charset)).to(device)\n",
    "        one_hot_data.scatter_(2, data[0].to(\n",
    "            device).unsqueeze(0).unsqueeze(2), 1)\n",
    "        output = model(one_hot_data.float())\n",
    "        pred_indices = output.argmax(dim=2).squeeze(0).cpu().tolist()\n",
    "        predicted_smiles = unvectorize_smiles(pred_indices, charset)\n",
    "\n",
    "        # Remove \"#\" characters\n",
    "        cleaned_smiles = predicted_smiles.replace(\"#\", \"\")\n",
    "\n",
    "        # Check for \"nan\" or \"inf\" in the SMILES string\n",
    "        if \"nan\" not in cleaned_smiles.lower() and \"inf\" not in cleaned_smiles.lower():\n",
    "            return cleaned_smiles\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return mol is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions_3.txt\", \"w\") as f:\n",
    "    for input_smiles in val_data:\n",
    "        predicted_smiles = predict(model, input_smiles, charset, max_length)\n",
    "        if predicted_smiles is not None and is_valid_smiles(predicted_smiles):\n",
    "            f.write(predicted_smiles + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ails-fcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
