{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit:  2022.09.5\n"
     ]
    }
   ],
   "source": [
    "#from fcd import get_fcd, load_ref_model, canonical_smiles, get_predictions, calculate_frechet_distance\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pickle\n",
    "import rdkit\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Ignore some warnings from RDKIT and keras\n",
    "from rdkit import RDLogger, Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load methods from the FCD library\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"RDKit: \", rdkit.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"smiles_train.txt\", header=None)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_canonical(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return Chem.MolToSmiles(mol, canonical=True)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_canonical = data.apply(to_canonical).dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_canonical.to_csv(\"canonical_smiles_train.txt\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_canonical = pd.read_csv(\n",
    "    \"canonical_smiles_train.txt\", header=None, squeeze=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                COc1ccc(N2CCN(C(=O)c3cc4ccccc4[nH]3)CC2)cc1\n",
       "1            c1ccc(CCCNC2CCCCN(CCOC(c3ccccc3)c3ccccc3)C2)cc1\n",
       "2                             Nc1nc(O)c(Br)c(-c2cccc(O)c2)n1\n",
       "3               CCc1nc2ccc(Br)cc2c(=O)n1-c1nc2c(C)cc(C)cc2s1\n",
       "4            O=c1cnn(-c2ccc(S(=O)(=O)N3CCCCC3)cc2)c(=O)[nH]1\n",
       "                                 ...                        \n",
       "1036638                  CCOc1ccc(-n2c(SC)nc3c(c2=O)SCC3)cc1\n",
       "1036639        Nc1ncnc2c1nc(I)n2C1SC(COC(=O)c2ccccc2)C(O)C1O\n",
       "1036640              O=C(O)CCc1sc(C=C2NC(=O)CS2)nc1-c1ccccn1\n",
       "1036641    CN(c1ncnc2[nH]ccc12)C1CC(CS(=O)(=O)N2CCC(C#N)C...\n",
       "1036642    CCc1ccc(S(=O)(=O)NC2c3cc(C(=O)NCCc4c[nH]cn4)cc...\n",
       "Name: 0, Length: 1036643, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, val_data = train_test_split(data, test_size=1/6, random_state=42)\n",
    "train_data, val_data = train_test_split(\n",
    "    data_canonical, test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = sorted(list(set(''.join(data_canonical))))\n",
    "max_length = max([len(smile) for smile in data_canonical]) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_smiles(smiles, charset, max_length):\n",
    "    indices = [charset.index(char) for char in smiles]\n",
    "    padded_indices = indices + [0] * (max_length - len(indices))\n",
    "    data = torch.tensor(padded_indices[:-1], dtype=torch.long)\n",
    "    target = torch.tensor(padded_indices[1:], dtype=torch.long)\n",
    "    return data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, smiles_data, charset, max_length):\n",
    "        self.smiles_data = smiles_data\n",
    "        self.charset = charset\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_smiles = self.smiles_data[index % len(self.smiles_data)]\n",
    "        data, target = vectorize_smiles(\n",
    "            input_smiles, self.charset, self.max_length)\n",
    "        one_hot_data = torch.zeros(data.size(0), len(self.charset))\n",
    "        one_hot_data.scatter_(1, data.unsqueeze(1), 1)\n",
    "        return one_hot_data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SMILESDataset(train_data, charset, max_length)\n",
    "val_dataset = SMILESDataset(val_data, charset, max_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "input_size = len(charset)\n",
    "hidden_size = 128#512\n",
    "output_size = len(charset)\n",
    "num_layers = 3\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedSMILESGRU(nn.Module):\n",
    "    def __init__(self, input_size=input_size, hidden_size=512, output_size=output_size, num_layers=3):\n",
    "        super(SimplifiedSMILESGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size,\n",
    "                          num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0),\n",
    "                         self.hidden_size).to(device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimplifiedSMILESGRU(input_size, hidden_size,\n",
    "                            output_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50:  57%|█████▋    | 3696/6480 [00:49<00:34, 80.29it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_count = 0\n",
    "    for one_hot_data, target in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "        one_hot_data, target = one_hot_data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(one_hot_data.float())\n",
    "\n",
    "        loss = criterion(output.transpose(1, 2), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_count += 1\n",
    "\n",
    "    avg_train_loss = train_loss / train_count\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_count = 0\n",
    "    with torch.no_grad():\n",
    "        for one_hot_data, target in tqdm(val_loader, desc=f\"Validating Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "            one_hot_data, target = one_hot_data.to(device), target.to(device)\n",
    "            output = model(one_hot_data.float())\n",
    "            loss = criterion(output.transpose(1, 2), target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_count\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"trained_model_lstm_4.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SMILESLSTM(\n",
       "  (lstm1): LSTM(37, 128, batch_first=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (lstm2): LSTM(128, 128, batch_first=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (lstm3): LSTM(128, 128, batch_first=True)\n",
       "  (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  (lstm4): LSTM(128, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"trained_model_lstm_epoch37.pth\"))\n",
    "#model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unvectorize_smiles(vector, charset):\n",
    "    smiles = \"\"\n",
    "    for index in vector:\n",
    "        if index == len(charset) - 1:  # End of sequence token\n",
    "            break\n",
    "        smiles += charset[index]\n",
    "    return smiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, input_smiles, charset, max_length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = vectorize_smiles(input_smiles, charset, max_length)\n",
    "        one_hot_data = torch.zeros(1, data[0].size(0), len(charset)).to(device)\n",
    "        one_hot_data.scatter_(2, data[0].to(\n",
    "            device).unsqueeze(0).unsqueeze(2), 1)\n",
    "        output = model(one_hot_data.float())\n",
    "        pred_indices = output.argmax(dim=2).squeeze(0).cpu().tolist()\n",
    "        predicted_smiles = unvectorize_smiles(pred_indices, charset)\n",
    "\n",
    "        # Remove \"#\" characters\n",
    "        cleaned_smiles = predicted_smiles.replace(\"#\", \"\")\n",
    "\n",
    "        # Check for \"nan\" or \"inf\" in the SMILES string\n",
    "        if \"nan\" not in cleaned_smiles.lower() and \"inf\" not in cleaned_smiles.lower():\n",
    "            return cleaned_smiles\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return mol is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_count = 0\n",
    "with open(\"predictions_lstm_4.txt\", \"w\") as f:\n",
    "    for input_smiles in val_data:\n",
    "        predicted_smiles = predict(model, input_smiles, charset, max_length)\n",
    "        #print(f\"Predicted SMILES: {predicted_smiles}\")\n",
    "        if predicted_smiles is not None and is_valid_smiles(predicted_smiles):\n",
    "            f.write(predicted_smiles + \"\\n\")\n",
    "            valid_count += 1\n",
    "            if valid_count >= 10001:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_smiles, charset, max_length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = vectorize_smiles(input_smiles, charset, max_length)\n",
    "        one_hot_data = torch.zeros(1, data[0].size(0), len(charset)).to(device)\n",
    "        one_hot_data.scatter_(2, data[0].to(\n",
    "            device).unsqueeze(0).unsqueeze(2), 1)\n",
    "        output = model(one_hot_data.float())\n",
    "        pred_indices = output.argmax(dim=2).squeeze(0).cpu().tolist()\n",
    "        predicted_smiles = unvectorize_smiles(pred_indices, charset)\n",
    "\n",
    "        # Check for \"nan\" or \"inf\" in the SMILES string\n",
    "        if \"nan\" not in predicted_smiles.lower() and \"inf\" not in predicted_smiles.lower():\n",
    "            return predicted_smiles\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "with open(\"predictions_lstm.txt\", \"w\") as f:\n",
    "    valid_count = 0\n",
    "    for input_smiles in val_data:\n",
    "        predicted_smiles = predict(model, input_smiles, charset, max_length)\n",
    "        if predicted_smiles is not None and is_valid_smiles(predicted_smiles):\n",
    "            f.write(predicted_smiles + \"\\n\")\n",
    "            valid_count += 1\n",
    "            if valid_count >= 10:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ails-fcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
