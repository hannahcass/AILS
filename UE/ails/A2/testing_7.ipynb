{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit:  2022.03.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pickle\n",
    "import rdkit\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import functools\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rdkit.Chem import Draw\n",
    "# from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "\n",
    "# Ignore some warnings from RDKIT and keras\n",
    "from rdkit import RDLogger, Chem\n",
    "from torch.nn.functional import one_hot\n",
    "import itertools\n",
    "from functools import reduce\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load methods from the FCD library\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"RDKit: \", rdkit.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"smiles_train.txt\", \"r\") as f:\n",
    "    smiles = []\n",
    "    for line in f:\n",
    "        mol = Chem.MolFromSmiles(line.strip())\n",
    "        if mol is not None:\n",
    "            smiles.append(Chem.MolToSmiles(mol))\n",
    "\n",
    "\n",
    "with open(\"smiles_train.smi\", \"w\") as f:\n",
    "    for s in smiles:\n",
    "        f.write(s + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "__encoders__ = {\n",
    "    0: \"<PAD>\",\n",
    "    1: \"<EOS>\",\n",
    "    2: \"<BOS>\",\n",
    "}\n",
    "max_length = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESDATA(torch_data.DataLoader):\n",
    "    def __init__(self, smiles, max_length):\n",
    "        self.smiles = open(smiles, 'r').read().split(\"\\n\")[:-1]\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        tokens = functools.reduce(\n",
    "            lambda acc, s: acc.union(set(s)), self.smiles, set())\n",
    "        self.vocsize = len(tokens) + len(__encoders__)\n",
    "        self.index2token = dict(enumerate(tokens, start=3))\n",
    "        self.index2token.update(__encoders__)\n",
    "        self.token2index = {v: k for k, v in self.index2token.items()}\n",
    "        self.ints = [torch.LongTensor([self.token2index[s] for s in line]) for line in \n",
    "            self.smiles]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "    \n",
    "    def decode(self, indexes):\n",
    "        return \"\".join([self.index2token[index] for index in indexes if index not in __encoders__])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        special_added = torch.cat((torch.LongTensor([self.token2index['<BOS>']]), self.ints[i], torch.LongTensor([self.token2index['<EOS>']]),\n",
    "                                   torch.LongTensor([self.token2index[\"<PAD>\"]]*(self.max_length-len(self.ints[i])-2))), dim=0)\n",
    "        return one_hot(special_added, self.vocsize).float(), special_added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_size = 512\n",
    "num_layers = 3\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "dropout = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SMILESDATA('smiles_train.smi', max_length)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedSMILESGRU(nn.Module):\n",
    "    def __init__(self, vocsize, hidden_size=512, num_layers=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.vocsize = vocsize\n",
    "\n",
    "        self.gru = nn.GRU(vocsize, hidden_size, num_layers,\n",
    "                          batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, vocsize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.gru(x)[0]\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def sample(self, batch_size=128, max_len=130):\n",
    "        bos_token = [k for k, v in __encoders__.items() if v == \"<BOS>\"][0]\n",
    "        x = torch.LongTensor([bos_token]*batch_size)\n",
    "        h = torch.zeros((self.num_layers, batch_size,\n",
    "                        self.hidden_size)).to(device)\n",
    "        accumulator = torch.zeros(batch_size, max_len)\n",
    "        for i in range(max_len):\n",
    "            x = one_hot(x, self.vocsize).float().unsqueeze(1).to(device)\n",
    "            output, h = self.gru(x, h)\n",
    "            next = F.softmax(self.linear(output).squeeze(1), dim=1)\n",
    "            x = torch.multinomial(next, num_samples=1,\n",
    "                                  replacement=True).squeeze(1)\n",
    "            accumulator[:, i] = x\n",
    "        return accumulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimplifiedSMILESGRU(dataset.vocsize, hidden_size, num_layers, dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Train Loss: 0.3421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/2], Train Loss: 0.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_count = 0\n",
    "    for i, (batch, target) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch}/{num_epochs}\", leave=False)):\n",
    "\n",
    "        batch, target = batch.to(device), target.to(device)\n",
    "        output = model(batch)\n",
    " \n",
    "        #print(\"Output shape:\", output.shape)\n",
    "        #print(\"Target shape:\", target.shape)\n",
    "        output = output.transpose(2, 1)\n",
    "        loss = criterion(output[:, :, :-1], target[:, 1:])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_count += 1\n",
    "\n",
    "    avg_train_loss = train_loss / train_count\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    scheduler.step(avg_train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'tokenizer': dataset.index2token,\n",
    "            'model': model.cpu()}, \"gru_model_1.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = torch.load('gru_model_1.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return mol is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SimplifiedSMILESGRU' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> 4\u001b[0m res \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49msample(\u001b[39m64\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m valid_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpredictions_new_1.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[39], line 23\u001b[0m, in \u001b[0;36mSimplifiedSMILESGRU.sample\u001b[1;34m(self, batch_size, max_len)\u001b[0m\n\u001b[0;32m     20\u001b[0m bos_token \u001b[39m=\u001b[39m [k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m __encoders__\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<BOS>\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     21\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor([bos_token]\u001b[39m*\u001b[39mbatch_size)\n\u001b[0;32m     22\u001b[0m h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, batch_size,\n\u001b[1;32m---> 23\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size))\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m     24\u001b[0m accumulator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(batch_size, max_len)\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_len):\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\dlnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SimplifiedSMILESGRU' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "\n",
    "model, tokenizer = trained_model['model'], trained_model['tokenizer']\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "res = model.sample(64)\n",
    "valid_count = 0\n",
    "with open(\"predictions_new_1.txt\", \"w\") as f:\n",
    "    while valid_count < 10001:\n",
    "        print(smiles, is_valid_smiles(smiles))\n",
    "        for i in range(res.size(0)):\n",
    "            smiles = \"\".join([tokenizer.decode([index]).strip()\n",
    "                            for index in res[i].tolist() if index not in __encoders__])\n",
    "            if is_valid_smiles(smiles):\n",
    "                f.write(smiles + os.linesep)\n",
    "                valid_count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
